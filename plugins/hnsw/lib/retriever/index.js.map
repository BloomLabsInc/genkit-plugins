{"version":3,"sources":["../../src/retriever/index.ts"],"sourcesContent":["/**\n * Copyright 2024 The Fire Company\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { GoogleGenerativeAIEmbeddings } from '@langchain/google-genai';\nimport { HNSWLib } from 'langchain/vectorstores';\nimport { generate } from '@genkit-ai/ai';\nimport { geminiPro as geminiProModel } from '@genkit-ai/googleai';\n\nimport { RetrieverFlowOptions, PluginOptions } from '../interfaces';\n\nconst generateHistories = (contexts: any[]) => {\n  const histories: any[] = [];\n  contexts.forEach((context: string) => {\n    histories.push({\n      role: 'user',\n      content: [{ text: context }],\n    });\n    histories.push({\n      role: 'model',\n      content: [{ text: 'Understood' }],\n    });\n  });\n  return histories;\n};\n\nconst initializeStore = async (\n  vectorStorePath: string,\n  apiKey: string | undefined\n) => {\n  const store = await HNSWLib.load(\n    vectorStorePath,\n    new GoogleGenerativeAIEmbeddings({\n      apiKey,\n    })\n  );\n  return store;\n};\n\nconst getContextBasedOnPrompt = async (store: HNSWLib, prompt: string) => {\n  const data = await store.similaritySearch(prompt, 1);\n  const context: string[] = [];\n  data.forEach((item: { pageContent: any }, i: any) => {\n    context.push(`${item.pageContent}`);\n  });\n  return context;\n};\n\nconst retrieveResponseWithVector = async (\n  flowOptions: RetrieverFlowOptions,\n  pluginOptions: PluginOptions\n) => {\n  const {\n    prompt,\n    indexPath,\n    temperature,\n    maxOutputTokens,\n    topK,\n    topP,\n    stopSequences,\n  } = flowOptions;\n  const { apiKey } = pluginOptions;\n\n  const store = await initializeStore(indexPath, apiKey);\n  const context = await getContextBasedOnPrompt(store, prompt);\n  const histories = generateHistories(context);\n  const retrievalConfig = {\n    temperature: temperature || 0.1,\n    maxOutputTokens: maxOutputTokens || 500,\n    topK: topK || 1,\n    topP: topP || 0,\n    stopSequences: stopSequences || [],\n  };\n  const promptResult = await generate({\n    history: histories,\n    prompt,\n    model: geminiProModel,\n    config: retrievalConfig,\n  });\n\n  return promptResult.text();\n};\n\nexport { retrieveResponseWithVector };\n"],"mappings":";;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAgBA,0BAA6C;AAC7C,0BAAwB;AACxB,gBAAyB;AACzB,sBAA4C;AAI5C,MAAM,oBAAoB,CAAC,aAAoB;AAC7C,QAAM,YAAmB,CAAC;AAC1B,WAAS,QAAQ,CAAC,YAAoB;AACpC,cAAU,KAAK;AAAA,MACb,MAAM;AAAA,MACN,SAAS,CAAC,EAAE,MAAM,QAAQ,CAAC;AAAA,IAC7B,CAAC;AACD,cAAU,KAAK;AAAA,MACb,MAAM;AAAA,MACN,SAAS,CAAC,EAAE,MAAM,aAAa,CAAC;AAAA,IAClC,CAAC;AAAA,EACH,CAAC;AACD,SAAO;AACT;AAEA,MAAM,kBAAkB,OACtB,iBACA,WACG;AACH,QAAM,QAAQ,MAAM,4BAAQ;AAAA,IAC1B;AAAA,IACA,IAAI,iDAA6B;AAAA,MAC/B;AAAA,IACF,CAAC;AAAA,EACH;AACA,SAAO;AACT;AAEA,MAAM,0BAA0B,OAAO,OAAgB,WAAmB;AACxE,QAAM,OAAO,MAAM,MAAM,iBAAiB,QAAQ,CAAC;AACnD,QAAM,UAAoB,CAAC;AAC3B,OAAK,QAAQ,CAAC,MAA4B,MAAW;AACnD,YAAQ,KAAK,GAAG,KAAK,WAAW,EAAE;AAAA,EACpC,CAAC;AACD,SAAO;AACT;AAEA,MAAM,6BAA6B,OACjC,aACA,kBACG;AACH,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,IAAI;AACJ,QAAM,EAAE,OAAO,IAAI;AAEnB,QAAM,QAAQ,MAAM,gBAAgB,WAAW,MAAM;AACrD,QAAM,UAAU,MAAM,wBAAwB,OAAO,MAAM;AAC3D,QAAM,YAAY,kBAAkB,OAAO;AAC3C,QAAM,kBAAkB;AAAA,IACtB,aAAa,eAAe;AAAA,IAC5B,iBAAiB,mBAAmB;AAAA,IACpC,MAAM,QAAQ;AAAA,IACd,MAAM,QAAQ;AAAA,IACd,eAAe,iBAAiB,CAAC;AAAA,EACnC;AACA,QAAM,eAAe,UAAM,oBAAS;AAAA,IAClC,SAAS;AAAA,IACT;AAAA,IACA,OAAO,gBAAAA;AAAA,IACP,QAAQ;AAAA,EACV,CAAC;AAED,SAAO,aAAa,KAAK;AAC3B;","names":["geminiProModel"]}